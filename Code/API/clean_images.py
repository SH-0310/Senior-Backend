import os
import sys
import requests
import json
import time
import logging
import re

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))
from utils import get_db_connection

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler()]
)

def check_url_alive(url):
    if not url: return None
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    
    # âœ… íŒ: ìµœê·¼ ê³µê³µë°ì´í„° ì‚¬ì§„ì€ httpsì—ì„œë§Œ ì—´ë¦¬ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
    # http ì£¼ì†Œë¥¼ httpsë¡œ ìš°ì„  ë³€í™˜í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    target_url = url.replace("http://", "https://")
    
    try:
        # ì£¼ì†Œ í™•ì¸ íƒ€ì„ì•„ì›ƒ 15ì´ˆë¡œ ì—°ì¥
        res = requests.head(target_url, timeout=15, allow_redirects=True, headers=headers, verify=False)
        if res.status_code == 200:
            return target_url
        
        # https ì‹¤íŒ¨ ì‹œ ì›ë³¸ httpë¡œ ì¬ì‹œë„
        res = requests.head(url, timeout=10, allow_redirects=True, headers=headers)
        if res.status_code == 200:
            return url
    except:
        pass
    return None

def run_recent_cleanup():
    conn = get_db_connection()
    conn.autocommit(True)
    
    with open('api_config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)[0]

    api_url = "http://apis.data.go.kr/B551011/PhotoGalleryService1/gallerySyncDetailList1"

    try:
        with conn.cursor() as cursor:
            # ìµœê·¼ 2ì‹œê°„ ì´ë‚´ ì‘ì—…ë¶„ (ë²”ìœ„ í™•ì¥)
            cursor.execute("""
                SELECT contentid, title, firstimage 
                FROM picnic_spots 
                WHERE last_sync_at >= NOW() - INTERVAL 2 HOUR
            """)
            targets = cursor.fetchall()
            
            logging.info(f"ğŸ” ì´ {len(targets)}ê°œì˜ ì¥ì†Œ ì •ë°€ ì¬ê²€í†  (ì´ˆê°•ë ¥ ë²„ì „)")

            for row in targets:
                c_id = row['contentid'] if isinstance(row, dict) else row[0]
                title = row['title'] if isinstance(row, dict) else row[1]
                current_img = row['firstimage'] if isinstance(row, dict) else row[2]

                # 1. ê¸°ì¡´ ì£¼ì†Œ ê²€ì¦ (ì´ë¯¸ ë¹„ì›Œì¡Œë‹¤ë©´ ìˆ˜ì§‘ ëª¨ë“œë¡œ ë°”ë¡œ ì§„ì…)
                if current_img:
                    alive_url = check_url_alive(current_img)
                    if alive_url:
                        logging.info(f"  âœ… [{title}] ì´ë¯¸ ì •ìƒ")
                        continue

                # 2. 404ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ì¬ìˆ˜ì§‘
                logging.warning(f"  ğŸš¨ [{title}] ìœ íš¨í•œ ì‚¬ì§„ ì°¾ëŠ” ì¤‘...")
                search_title = re.sub(r'\(.*\)|\[.*\]', '', title).strip()
                
                params = {
                    "serviceKey": config["SERVICE_KEY"],
                    "MobileApp": config["MOBILE_APP"], "MobileOS": "ETC",
                    "numOfRows": 15, "pageNo": 1, "_type": "json", "title": search_title
                }

                try:
                    # âœ… íƒ€ì„ì•„ì›ƒì„ 60ì´ˆë¡œ ëŒ€í­ ì—°ì¥ (ì„œë²„ê°€ ëŠë ¤ë„ ëê¹Œì§€ ê¸°ë‹¤ë¦¼)
                    res = requests.get(api_url, params=params, timeout=60)
                    res_json = res.json()
                    items_node = res_json.get("response", {}).get("body", {}).get("items", "")
                    
                    if not isinstance(items_node, dict):
                        logging.info(f"  â„¹ï¸ [{title}] API ë°ì´í„° ì—†ìŒ")
                        continue

                    items = items_node.get("item", [])
                    if not isinstance(items, list): items = [items]

                    new_img = None
                    for item in items:
                        val_url = check_url_alive(item.get("galWebImageUrl"))
                        if val_url:
                            new_img = val_url
                            break
                    
                    if new_img:
                        cursor.execute("UPDATE picnic_spots SET firstimage = %s WHERE contentid = %s", (new_img, c_id))
                        logging.info(f"  âœ¨ [{title}] ì‚¬ì§„ ë³µêµ¬ ì™„ë£Œ!")
                    else:
                        # âš ï¸ 404ê°€ í™•ì‹¤í•  ë•Œë§Œ ë¹„ì›Œë‘ 
                        logging.error(f"  âŒ [{title}] ëª¨ë“  ì‚¬ì§„ ë§Œë£Œ í™•ì¸")

                except (requests.exceptions.Timeout, requests.exceptions.ConnectionError):
                    logging.error(f"  â±ï¸ [{title}] ì„œë²„ ì‘ë‹µ ì—†ìŒ (ê±´ë„ˆëœ€)")
                except Exception as e:
                    logging.error(f"  âš ï¸ [{title}] ì—ëŸ¬: {str(e)[:50]}")
                
                time.sleep(0.5)

    finally:
        conn.close()

if __name__ == "__main__":
    run_recent_cleanup()