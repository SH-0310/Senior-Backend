import time, requests, logging, pymysql
from datetime import datetime
from dateutil.relativedelta import relativedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options

# âœ… ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸
from utils import extract_all_keywords, get_db_connection

# --- ì„¤ì • ë° ìƒìˆ˜ ---
AGENCY_NAME = "í•˜ë‚˜íˆ¬ì–´"
HANA_PHONE = "1577-1233"
TELEGRAM_TOKEN = "8543857876:AAFs2kEURQEihK6_j6mw2PPaKQO4gYoBoSM"
CHAT_ID = "8305877092"

logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler("/home/ubuntu/Senior/Code/hanatour_crawler.log", encoding='utf-8'), 
        logging.StreamHandler()
    ]
)

def get_automated_cookies():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.page_load_strategy = 'eager' 
    service = Service("/usr/bin/chromedriver")
    try:
        driver = webdriver.Chrome(service=service, options=options)
        driver.get("https://www.hanatour.com/package/major-products?pkgServiceCd=DP&trvlDayCnt=1")
        time.sleep(7)
        cookies = driver.get_cookies()
        return "; ".join([f"{c['name']}={c['value']}" for c in cookies])
    finally:
        driver.quit()

def fetch_sale_products_by_day(rprs_code, dep_day, cookie):
    """í•´ë‹¹ ë‚ ì§œì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  íŒë§¤ ìƒí’ˆ(saleProdCd)ì˜ prefix/suffix/ê°€ê²© ì •ë³´ë¥¼ ì¶”ì¶œ"""
    if not dep_day: return []
    url = "https://gw.hanatour.com/front/package/products?_siteId=hanatour"
    
    headers = {
        "Content-Type": "application/json",
        "Cookie": cookie,
        "Referer": "https://www.hanatour.com/",
        "Origin": "https://www.hanatour.com",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36 Edg/143.0.0.0",
        "prgmid": "major-products",
        "accept": "application/json, text/plain, */*"
    }
    
    payload = {
        "header": {
            "timestamp": datetime.now().strftime("%Y%m%d%H%M%S"),
            "lang": "ko", "browserEngine": "Edge", "browserVersion": "143.0.0.0",
            "osName": "Windows", "osVersion": "10", "pathCd": "DCP", "siteId": "hanatour", "userDevice": "PC"
        },
        "domain": "https://www.hanatour.com",
        "scods": "B1,B2,B3,B4,B5,B6,B7,B8,A8,A9",
        "areaCd": "AK", "pkgServiceCd": "DP", "trvlDayCnt": "1",
        "strtDepDay": dep_day, "endDepDay": dep_day, "rprsProdCds": rprs_code,
        "page": 1, "pageSize": 20, "sort": "PROD_SORT5", "os": "pc"
    }
    
    results = []
    try:
        res = requests.post(url, json=payload, headers=headers, timeout=10)
        products = res.json().get('data', {}).get('products', [])
        for p in products:
            sale_cd = p.get('saleProdCd')
            if sale_cd and len(sale_cd) >= 9:
                results.append({
                    'prefix': sale_cd[:6],
                    'suffix': sale_cd[-3:],
                    'title': p.get('saleProdNm'),
                    'price': p.get('adtAmt'), # ë‚ ì§œ APIì˜ ê°€ê²©ë³´ë‹¤ ì‹¤ì œ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ì˜ ê°€ê²©ì´ ë” ì •í™•í•¨
                    'sale_cd': sale_cd
                })
        return results
    except Exception as e: 
        logging.error(f"ìƒì„¸ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    return []

def fetch_calendar(rprs_code, month_str, cookie):
    url = "https://gw.hanatour.com/front/package/calendar/departure-dates?_siteId=hanatour"
    headers = {"Content-Type": "application/json", "Cookie": cookie, "Referer": "https://www.hanatour.com/"}
    payload = {
        "header": {"timestamp": datetime.now().strftime("%Y%m%d%H%M%S"), "lang": "ko", "pathCd": "DCP", "siteId": "hanatour"},
        "domain": "https://www.hanatour.com", "rprsProdCds": rprs_code, "depDay": month_str, 
        "areaCd": "AK", "pkgServiceCd": "DP", "trvlDayCnt": "1", "os": "pc", "scods": "B1,B2,B3,B4,B5,B6,B7,B8,A8,A9"
    }
    try:
        res = requests.post(url, json=payload, headers=headers, timeout=10)
        return res.json().get('data', {}).get(month_str, [])
    except: return []

def send_telegram_msg(text):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": text}
    try: requests.post(url, data=payload, timeout=10)
    except Exception as e: logging.error(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")

def run_collection():
    start_time = datetime.now()
    logging.info(f"ğŸš€ {AGENCY_NAME} ì •ë°€ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (ê¸°ì¤€ ì‹œê°„: {start_time})")
    
    stats = {"total_rprs": 0, "saved_schedules": 0, "failed_codes": 0, "deleted_tours": 0}
    cookie = get_automated_cookies()
    if not cookie: return

    main_url = "https://gw.hanatour.com/front/package/major-products?_siteId=hanatour"
    main_payload = {
        "header": {"timestamp": datetime.now().strftime("%Y%m%d%H%M%S"), "lang": "ko"},
        "domain": "https://www.hanatour.com", "areaCd": "AK", "pkgServiceCd": "DP", "trvlDayCnt": "1",
        "pageSize": 100, "sort": "RPRS_SORT2", "strtDepDay": datetime.now().strftime("%Y%m%d"), "os": "pc"
    }

    try:
        response = requests.post(main_url, json=main_payload, headers={"Content-Type": "application/json", "Cookie": cookie})
        products = response.json().get('data', {}).get('products', [])
        
        conn = get_db_connection()
        conn.autocommit(True) 
        
        now_dt = datetime.now()
        one_month_later = now_dt + relativedelta(months=1)
        today_str, limit_day_str = now_dt.strftime("%Y%m%d"), one_month_later.strftime("%Y%m%d")

        with conn.cursor() as cursor:
            for p in products:
                rprs_code = p.get('rprsProdCd')
                title = p.get('rprsProdNm')
                
                # 1ï¸âƒ£ [ë‚ ì§œ í™•ì¸ ë¨¼ì €] 1ê°œì›” ë‚´ ì¶œë°œ ê°€ëŠ¥í•œ ë‚ ì§œê°€ ìˆëŠ”ì§€ ì²´í¬
                all_schedules = []
                months = [now_dt.strftime("%Y%m"), one_month_later.strftime("%Y%m")]
                for m in months:
                    all_schedules.extend(fetch_calendar(rprs_code, m, cookie))
                
                all_schedules = [s for s in all_schedules if today_str <= s.get('depDay') <= limit_day_str]

                # 2ï¸âƒ£ [ì¡°ê±´ë¶€ ì €ì¥] ë‚ ì§œê°€ ì—†ìœ¼ë©´ tours í…Œì´ë¸”ì—ë„ ë„£ì§€ ì•Šê³  ì¦‰ì‹œ ê±´ë„ˆëœ€
                if not all_schedules:
                    # ì´ì „ì— ì €ì¥ë˜ì–´ ìˆë˜ ìƒí’ˆì´ì—ˆë‹¤ë©´, ë§ˆì§€ë§‰ì˜ ìœ ë ¹ ìƒí’ˆ ì •ë¦¬ ë¡œì§ì—ì„œ ìë™ ì‚­ì œë©ë‹ˆë‹¤.
                    continue

                # 3ï¸âƒ£ [ë¶€ëª¨ í…Œì´ë¸” ì €ì¥] ë‚ ì§œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ tours ì •ë³´ë¥¼ ì…ë ¥/ê°±ì‹ 
                location = p.get('trstCityNmLstCont')
                categories = extract_all_keywords(title)
                sql_tours = """
                    INSERT INTO tours (product_code, title, description, location, collected_at, agency, category, phone, is_priority)
                    VALUES (%s, %s, %s, %s, NOW(), %s, %s, %s, 0)
                    ON DUPLICATE KEY UPDATE title=%s, location=%s, category=%s, collected_at=NOW()
                """
                cursor.execute(sql_tours, (rprs_code, title, title, location, AGENCY_NAME, categories, HANA_PHONE, title, location, categories))
                stats["total_rprs"] += 1

                # 4ï¸âƒ£ [ìì‹ í…Œì´ë¸” ì €ì¥] ì„¸ë¶€ ì¼ì • ì •ë³´ ì…ë ¥
                # --- [ìì‹ í…Œì´ë¸” ì €ì¥] ì„¸ë¶€ ì¼ì • ì •ë³´ ì…ë ¥ ë£¨í”„ ë‚´ë¶€ ---
                for s in all_schedules:
                    raw_dep_date = s.get('depDay') # ì˜ˆ: "20260131"
                    
                    # âœ… ì—¬ê¸°ì„œ í•˜ì´í”ˆì´ ë“¤ì–´ê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (20260131 -> 2026-01-31)
                    dep_date = f"{raw_dep_date[:4]}-{raw_dep_date[4:6]}-{raw_dep_date[6:]}"
                    
                    # ìƒì„¸ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ í˜¸ì¶œ
                    sale_list = fetch_sale_products_by_day(rprs_code, raw_dep_date, cookie) 
                    # ì£¼ì˜: API í˜¸ì¶œ ì‹œì—ëŠ” ì›ë˜ì˜ 8ìë¦¬(raw_dep_date)ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

                    if not sale_list: continue

                    for sp in sale_list:
                        # ì˜ˆì•½ URL ìƒì„± (URLì—ë„ 8ìë¦¬ ë‚ ì§œ í˜•ì‹ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸ í•„ìš”)
                        # í•˜ë‚˜íˆ¬ì–´ URL ê·œì¹™ì— ë”°ë¼ raw_dep_date[2:] ë“±ì„ ì ì ˆíˆ ì‚¬ìš©
                        booking_url = f"https://www.hanatour.com/trp/pkg/CHPC0PKG0200M200?pkgCd={sp['prefix']}{raw_dep_date[2:]}{sp['suffix']}&prePage=major-products"
                        
                        cursor.execute("""
                            INSERT INTO tour_schedules (product_code, title, departure_date, price_text, booking_url, updated_at)
                            VALUES (%s, %s, %s, %s, %s, NOW()) 
                            ON DUPLICATE KEY UPDATE 
                                title = %s, 
                                price_text = %s, 
                                booking_url = %s, 
                                updated_at = NOW(), 
                                departure_date = %s  -- âœ… ì—…ë°ì´íŠ¸ ì‹œì—ë„ ë‚ ì§œ í˜•ì‹ì„ ìœ ì§€
                        """, (rprs_code, sp['title'], dep_date, sp['price'], booking_url, sp['title'], sp['price'], booking_url, dep_date))
                        stats["saved_schedules"] += 1
                
                logging.info(f" âœ… ë™ê¸°í™” ì™„ë£Œ: {title} ({len(all_schedules)}ê°œ ë‚ ì§œ í™•ì¸)")

            # 5ï¸âƒ£ [ì •ë¦¬ ë¡œì§] ì´ë²ˆ ì‹¤í–‰ì—ì„œ ë‚ ì§œê°€ í™•ì¸ë˜ì§€ ì•Šì€ ëª¨ë“  í•˜ë‚˜íˆ¬ì–´ ìƒí’ˆ ì œê±°
            # toursì—ì„œ ì‚­ì œë˜ë©´ tour_schedules ë°ì´í„°ë„ CASCADEì— ì˜í•´ í•¨ê»˜ ì§€ì›Œì§‘ë‹ˆë‹¤.
            cleanup_sql = "DELETE FROM tours WHERE agency = %s AND collected_at < %s"
            cursor.execute(cleanup_sql, (AGENCY_NAME, start_time))
            stats["deleted_tours"] = cursor.rowcount

            # âœ… [ì¶”ê°€] 5-1ï¸âƒ£ í¬ë¡¤ë§ ë¡œê·¸ ê¸°ë¡ (DB ì €ì¥)
            finish_time = datetime.now()
            log_sql = """
                INSERT INTO crawler_logs (agency_name, status, collected_count, crawled_at, message)
                VALUES (%s, %s, %s, %s, %s)
            """
            log_message = f"ë¶€ëª¨ {stats['total_rprs']}ì¢…, ì‚­ì œ {stats['deleted_tours']}ì¢…"
            cursor.execute(log_sql, (
                AGENCY_NAME, 
                "SUCCESS", 
                stats["saved_schedules"], 
                finish_time, 
                log_message
            ))

        # 6ï¸âƒ£ ë¦¬í¬íŠ¸ ë°œì†¡
        duration = datetime.now() - start_time
        report = (
            f"ğŸ¤– [{AGENCY_NAME} ë°ì´í„° ì •ì œ ì™„ë£Œ]\n"
            f"â± ì†Œìš”ì‹œê°„: {str(duration).split('.')[0]}\n"
            f"ğŸ“¦ ìœ íš¨ ìƒí’ˆ: {stats['total_rprs']}ì¢… (ë‚ ì§œ ì¡´ì¬)\n"
            f"ğŸ”¹ ìƒì„¸ ì¼ì •: {stats['saved_schedules']}ê±´\n"
            f"ğŸ§¹ ì‚­ì œëœ ë¬´íš¨ìƒí’ˆ: {stats['deleted_tours']}ì¢… (ë‚ ì§œ ì—†ìŒ)\n"
            f"--------------------------\n"
            f"â€» ì¶œë°œ ë¶ˆê°€ëŠ¥í•œ ìƒí’ˆì´ DBì—ì„œ ì™„ì „íˆ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
        send_telegram_msg(report)

    except Exception as e:
        logging.error(f"âŒ ì˜¤ë¥˜: {e}")
        # âœ… [ì¶”ê°€] ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ 'FAIL' ìƒíƒœë¡œ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
        try:
            with get_db_connection() as err_conn:
                with err_conn.cursor() as err_cursor:
                    err_cursor.execute("""
                        INSERT INTO crawler_logs (agency_name, status, crawled_at, message)
                        VALUES (%s, %s, %s, %s)
                    """, (AGENCY_NAME, "FAIL", datetime.now(), str(e)[:200]))
                    err_conn.commit()
        except: pass
        
        send_telegram_msg(f"âŒ {AGENCY_NAME} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)[:100]}")
    finally:
        if 'conn' in locals() and conn: conn.close()

if __name__ == "__main__":
    run_collection()